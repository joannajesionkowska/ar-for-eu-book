<!DOCTYPE html>
<html>

  ﻿<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Dialogue Understanding</title>
    <meta name="description" content="The Open Augmented Reality Teaching Book">

    <link rel="stylesheet" href="/ar-for-eu-book/css/main.css">
    <link rel="canonical" href="https://klamma.github.io/ar-for-eu-book/chapter/dialogue-understanding/">
    <link rel="alternate" type="application/rss+xml" title="The Open Augmented Reality Teaching Book" href="https://klamma.github.io/ar-for-eu-book/feed.xml">

    <!-- Favicon head tag -->
    <link rel="shortcut icon" href="/ar-for-eu-book/favicon.ico" type="image/x-icon">

    <!-- Visualization Libraries -->
    <script src="https://code.jquery.com/jquery-3.1.1.min.js"></script>
    <script src="https://code.highcharts.com/highcharts.js"></script>
    <script src="https://code.highcharts.com/highcharts-more.js"></script>
    <script src="https://code.highcharts.com/modules/exporting.js"></script>

    <!-- formula rendering -->
    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/ar-for-eu-book/">The Open Augmented Reality Teaching Book</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
	  <a class="page-link" href="https://codereality.net/">Code Reality</a>
          <a class="page-link" href="/ar-for-eu-book/posts">Blog Posts</a>
          <a class="page-link" href="/ar-for-eu-book/toc">Table of Content</a>
          <a class="page-link" href="/ar-for-eu-book/references">Bibliography</a>
          <a class="page-link" href="/ar-for-eu-book/contrib">Contributors</a>
          <a class="page-link" href="/ar-for-eu-book/about">About</a>
      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Dialogue Understanding</h1>
  </header>

  <div class="post-content">
    
<h2 id="contents">Contents</h2>
<ul>
  <li><a href="#part1">Part 1. Creating an IBM Cloud account</a></li>
  <li><a href="#part2">Part 2. Creating a Watson Assistant</a></li>
  <li><a href="#part3">Part 3. Creating a Chatbot</a></li>
  <li><a href="#part4">Part 4. Unity settings</a></li>
  <li><a href="#part5">Part 5. Using Watson in Unity3D</a></li>
</ul>

<h2 id="resources">Resources</h2>

<ul>
  <li>Download Unity ZIP file, and extract it https://drive.google.com/file/d/1idlhVW_N2PW0uEfk1DbOyXNuxc2n8If1/view?usp=sharing</li>
</ul>

<h2 id="software">Software</h2>
<ul>
  <li>Unity 3D (version 2018.3.14f1)</li>
</ul>

<h3 id="part1"><strong>Part 1. Creating an IBM Cloud account</strong></h3>

<p>Step 1.1: Register an account https://cloud.ibm.com/login &gt; create an IBM Cloud account &gt; you’ll be asked to verify your email &gt; complete personal information &gt; login your account and accept the privacy notices.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%201.1.png" alt="Image of Step 1.1" /></p>

<p><em><strong>Note:*</strong> *if you already have a Watson Assistant service running in your IBM Cloud account, and you can jump to the next part.</em></p>

<h3 id="part2"><strong>Part2.</strong> Creating a Watson Assistant</h3>

<p><strong>Step 2.1.</strong> Click on the Create resource button on the dashboard &gt; Watson Assistant (if you can’t find it, Catalog &gt; AI &gt; Watson Assistant) &gt; Click Create tab, and check the region.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%202.1.jpg" alt="Image of Step 2.1" /></p>

<p><strong>Step2.3.</strong> Launch Watson Assistant &gt; Create assistant, called AI training (or something else you like) &gt; Create assistant &gt; Add dialog skill &gt; Select “Create skill” &gt; Dessert &gt; Create dialog skill &gt; click on “Dessert”.</p>

<p><strong>Step 2.4.</strong> Create Speech to Text &amp; Text to Speech: Go back to the Dashboard &gt; Add services &gt; Catalog &gt; Services &gt; Select “AI” &gt; Click on Speech to Text &amp; Text to Speech &gt; Create. (they will be used in Unity)</p>

<h3 id="part3"><strong>Part 3.</strong> Creating a Chatbot</h3>

<p>In this tutorial, we will create a simple Chatbot that can be used in your 3D character model in Unity 3D.</p>

<p>Before that, let’s take example. If you call a dessert shop, what a seller will ask you questions? You may say hi, I’d like to order a chocolate cake, and the seller needs to know your name and phone number. So the dialogue will be like that:</p>

<table>
  <thead>
    <tr>
      <th>1. Seller</th>
      <th>Welcome to XXX shop, what can I do for you?</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2. User</td>
      <td>I’d like to order some desserts/cakes</td>
    </tr>
    <tr>
      <td>3. Seller</td>
      <td>How can I call you?/ What’s your name?</td>
    </tr>
    <tr>
      <td>4. User</td>
      <td>my name is XXXX</td>
    </tr>
    <tr>
      <td>5. Seller</td>
      <td>What desserts do you like? do you need a menu? Today, we have  specials.</td>
    </tr>
    <tr>
      <td>A user needs to make a choice.   1. The user directly orders a dessert; 2. He/she needs a menu. 3. The  seller gives some recommendations (specials)</td>
      <td> </td>
    </tr>
    <tr>
      <td>User</td>
      <td>I’d like to order XXXXXX</td>
    </tr>
    <tr>
      <td>6. Seller</td>
      <td>What’s your phone number?</td>
    </tr>
    <tr>
      <td>7.   User</td>
      <td>It’s 1234567890</td>
    </tr>
    <tr>
      <td>8.  Seller</td>
      <td>Thanks, we’ll send a message to you.</td>
    </tr>
  </tbody>
</table>

<p><em>Step 3.1- 3.10 introduces how to create the No.1-4 of the table; Step 3.11- 3.15 shows No.5; No.6-7 is on the Step 3.17-3.19.</em></p>

<p><strong>Notes:</strong></p>

<p>·    <em>Intents: the purpose of a user’s input. The Watson assistant can select the correct dialog flow by recognizing the intents.</em></p>

<p>·    <em>Entities: it shows information in the user input that is relevant to the user’s purpose.</em></p>

<p><strong>Step 3.1.</strong> Click on “Content Catalog” &gt; “General” can be added to skill (it includes lots of basic contents of conversation, like good morning. But in this tutorial, we are not going to use it)</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.1.png" alt="Image of Step 3.1" /></p>

<p><strong>Step 3.2.</strong> Select “Dialog” &gt; Click on the “Node options” on the Welcome node &gt; Add folder &gt; named Dessert.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.2.png" alt="Image of Step 3.2" /></p>

<p><strong>Step 3.3.</strong> Click on Intents &gt; Create Intent, called #welcome &gt; Create &gt; user example is Hi/hi, there; Hello/hello, there.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.3.png" alt="Image of Step 3.3" /></p>

<p><strong>Step 3.4.</strong> Go back to Dialog &gt; Click on Welcome node &gt; Condition (If assistant recognizes) is #welcome &gt; Customize the Welcome node prompt with (Assistant responds):</p>

<p>Hello, Welcome to AI dessert shop. How can I help you?</p>

<p>Hello, Welcome to AI dessert shop. What can I do for you? &gt; Response variations are set to random.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.4.png" alt="Image of Step 3.4" /></p>

<p><strong>Step 3.5.</strong> Click on “Node options” on the Dessert folder &gt; add node to folder, called Name &gt; Assistant responds: OK, how can I call you? / what’s your name? &gt; Response variations are set to random again.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.5.png" alt="Image of Step 3.5" /></p>

<p><strong>Step 3.6.</strong> Click on “Intents” &gt; Create Intent &gt; create a #name &gt; add example:</p>

<p>I’m @username.</p>

<p>call me @username.</p>

<p>my name is @username.</p>

<p><em><strong>Note:*</strong> *the first alphabet should be lowercase, if it’s capital, the assistant cannot recognize user’s name.</em></p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.6.png" alt="Image of Step 3.6" /></p>

<p><strong>Step 3.7.</strong> Create @username on an entity, Click on “Entities” &gt; My entities &gt; Create entities &gt; Entity name is @username &gt; value is name_syntax, type is Patterns, pattern is [A-Z][a-z]+ &gt; Add value.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.7.png" alt="Image of Step 3.7" /></p>

<p><strong>Step 3.8</strong>. Back to Entities &gt; Select “System entities” &gt; tick all boxes.</p>

<p><strong>Step 3.9.</strong> Click Intents tab &gt; Create intent &gt; named #order &gt; user example: hi, I’d like to order cakes.</p>

<p><strong>Step 3.10.</strong> Click on Dialog &gt; click on the icon of dessert folder &gt; select “Name” node &gt; create condition (If assistant recognizes): #intents &gt; select “#order”.</p>

<p><strong>Step 3.11.</strong> Click on node options on the Name node &gt; Add child node, called Dessert &gt; create condition: #name, add or, select @username, add or, select @sys-person &gt; there are node options on the right of Assistant responds &gt;  Select “Open context editor” &gt; Variable is username &gt; Value is “<? @sys-number.literal ?>” &gt; Assistant responds: What desserts would you like, $username?</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.11(1).png" alt="Image of Step 3.11(1)" /></p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.11(2).png" alt="Image of Step 3.11(2)" /></p>

<p><strong>Step 3.12.</strong> On the Dessert node &gt; add the other response type                                 &gt; Text: Do you need a menu? Or I can provide some specials?</p>

<p>There are three options, 1. I need a menu; 2. The assistant offers recommendations; 3. I know what I’d like to get.</p>

<p><strong>Step 3.13.</strong> Make a menu: Create a new intent, called #menu &gt; user examples:</p>

<p>I need a menu.</p>

<p>Pudding(/pudding) menu</p>

<p>Cake(/cake) menu</p>

<p>Could you give me some recommendations?</p>

<p>Specials (/specials)</p>

<p>&gt; Back to Dialog &gt; Create a new child node on the Dessert node, called menu &gt; condition is #menu &gt; Assistant responds: Ok, here is our menu. &gt; Add new response type &gt; Text changes to Option &gt; Title: Which dessert/ menu you like? &gt; List labels are Pudding and Cake, Value is pudding menu and cake menu.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.13(1).png" alt="Image of Step 3.13(1)" /></p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.13(2).png" alt="Image of Step 3.11(2)" /></p>

<p><strong>Step 3.14.</strong> Click Intents tab &gt; Create Intent called #alldesserts &gt; list more desserts as possible, including cakes and puddings.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.14.png" alt="Image of Step 3.14" /></p>

<p><strong>Step 3.15.</strong>  Go back to the Dialog &gt; create a new child node on the menu node, called pudding menu &gt; condition: #menu&gt; Assistant responds: We have chocolate puddings, vanilla puddings, and milk puddings &gt; Add child node on the pudding menu, called pudding finish &gt; condition is #alldesserts &gt; Assistant responds: No problem! &gt; Again, create a new child node on the menu node, called cake menu &gt; you turn, it’s the same way to create conditions!</p>

<p><strong>Note:</strong> It’s also possible that a client wants to know the cake menu after she/he chooses the pudding menu. Therefore, you need to think about how to create nodes and intents.</p>

<p><strong>Step 3.16.</strong>  It’s the same way to create the rest of two options (an assistant recommends a desserts (specials), and clients make choice).</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.16.png" alt="Image of Step 3.16" /></p>

<p><strong>Note:</strong> Don’t make wrong levels.</p>

<p><strong>Step 3.17.</strong> Add node below on the Dessert node, called phone number &gt; Assistant responds: What’s your phone number?</p>

<p><strong>Note:</strong> Don’t add any conditions.</p>

<p><strong>Step 3.18.</strong> Create a new intent called #phonenumber &gt; examples: my phone number is @sys-number; number is @sys-number &gt; click on Dialog &gt; Add a child node on the phone number node, called end &gt; conditions: #phonenumber, add or, select @sys-number &gt; assistant responds: Thanks, we’ll send a message to you. Have a nice day!</p>

<p><strong>Step 3.19.</strong> Select “pudding finish” node &gt; Wait for reply (on the “The assistant should”) needs to change to Jump on &gt; Select “phone number” node, and click on Respond.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.19(1).png" alt="Image of Step 3.19(1)" /></p>

<p><img src="../../assets/figures/dialogue_understanding/Step%203.19(2).png" alt="Image of Step 3.19(2)" /></p>

<p><strong>Note:</strong> All the end of options node, such as pudding finish node, cake finish node, and specials finish node should be Jump to phone number.</p>

<p><strong>Step 3.20.</strong> Now you can test your Chatbox. Click on “Try it”.</p>

<h3 id="part4"><strong>Part 4.</strong> Unity Settings</h3>

<p>This tutorial introduces how to use IBM Watson SDK in Unity 3D in order to interact with a 3D character based on your Chatbox.</p>

<p><strong>Step 4.1.</strong> Open Unity &gt; Create a new project, called Dialog understanding Unity &gt; Choose the file location.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%204.1.jpg" alt="Image of Step 4.1" /></p>

<p><strong>Step 4.2.</strong> Click on File &gt; Save as &gt; Scenes, called Dialog understanding</p>

<p><strong>Step 4.3.</strong> File &gt; Building Settings &gt; Select “Universal Windows Platform”&gt; Click Add Open scenes &gt; Target Device &gt;Select “PC” &gt; Build</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%204.3.jpg" alt="Image of Step 4.3" /></p>

<p><strong>Step 4.4.</strong> Click Edit &gt; Select “Player” &gt; Capabilities &gt; tick the box of Microphone.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%204.4.png" alt="Image of Step 4.4" /></p>

<h3 id="part5"><strong>Part 5.</strong> Using Watson in Unity3D</h3>

<p><strong>Step 5.1.</strong> Open the Unity file.</p>

<p><strong>Note:</strong> if there are lots of warnings and errors on the Console, please click Clear button.</p>

<p><strong>Step 5.2</strong>. Click on WatsonServices on Hierarchy widow, and open the “_scripts” file on Project window. Dialogue Services is the script of DialogueService, and it also links to Watson assistant. Speech Input Service is the script of SpeechInputServices, it links to Speech to Text service, and Speechoutput links to Text to Speech service in IBM Watson, that is applied to create a spoken sound version of the text. Please double click on the three services in Visual studio.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%205.2.png" alt="Image of Step 5.2" /></p>

<p><strong>Step 5.3.</strong> Go to your IBM Cloud Dashboard&gt; Services &gt; Watson Assistant &gt; Click on the copy icon to make note of the API key. The API key applies basic authentication, in here it’s the password. URL is location specific. So make sure your URL matches with your location.</p>

<p><strong>Note:</strong> However, if your URL is very long, it cannot work in Unity. For example, in this picture the URL should be https://api.eu-gb.assistant.watson.cloud.ibm.com</p>

<p><em>Service endpoints by location:</em></p>

<p>·    London: https://api.eu-gb.assistant.watson.cloud.ibm.com</p>

<p>·    Frankfurt: https://api.eu-de.assistant.watson.cloud.ibm.com</p>

<p>·    Washington, DC: https://api.us-east.assistant.watson.cloud.ibm.com</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%205.3.png" alt="Image of Step 5.3" /></p>

<p><strong>Step 5.4.</strong> Go back to Unity &gt; Paste it on your API key to Iam Apikey in the Dialogue Service, and also paste it to the corresponding script.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%205.4.png" alt="Image of Step 5.4" /></p>

<p><strong>Step 5.5.</strong> Again, copy the URL &gt; paste it to Service Url, ServiceURL, and ServiceURL (optional) on the script.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%205.5.png" alt="Image of Step 5.5" /></p>

<p><strong>Step 5.6.</strong> Launch Watson Assistant &gt; Select the node options on your Watson Assistant &gt; Settings &gt; Click on API Details &gt; copy Assistant ID to Unity and the script.</p>

<p><img src="../../assets/figures/dialogue_understanding/Step%205.6(1).png" alt="Image of Step 5.6(1)" /></p>

<p><img src="../../assets/figures/dialogue_understanding/Step%205.6(2).png" alt="Image of Step 5.6(2)" /></p>

<p><strong>Step 5.7.</strong> It’s the same way to copy API key and URL , and past it to your Unity and the corresponding scripts for Speech to Text &amp; Text to Speech.</p>

<p>Service of Speech to Text endpoints by location*</p>

<p>·    <em>Washington, DC:</em> <a href="https://api.us-east.speech-to-text.watson.cloud.ibm.com"><em>https://api.us-east.speech-to-text.watson.cloud.ibm.com</em></a></p>

<p>·    <em>Frankfurt:</em> <a href="https://api.eu-de.speech-to-text.watson.cloud.ibm.com"><em>https://api.eu-de.speech-to-text.watson.cloud.ibm.com</em></a></p>

<p>·    <em>London:</em> <a href="https://api.eu-gb.speech-to-text.watson.cloud.ibm.com"><em>https://api.eu-gb.speech-to-text.watson.cloud.ibm.com</em></a></p>

<p>​       <br />
​       <br />
​         <em>Service of Text to Speech endpoints by location</em>
​       <br />
​         ·    Washington DC: https://api.us-east.text-to-speech.watson.cloud.ibm.com
​       <br />
​         ·    Frankfurt: https://api.eu-de.text-to-speech.watson.cloud.ibm.com
​       <br />
​         ·    London: https://api.eu-gb.text-to-speech.watson.cloud.ibm.com
​       <br />
​       <br />
​       <br />
​         <strong>Step 5.8.</strong> Before playing it, we need to configure your service credentials. Save unity file (Ctrl+S), close Unity &gt; open the location of the Unity file &gt; find ibm_credentials.env, and open it.
​       <br />
​         <img src="../../assets/figures/dialogue_understanding/Step%205.8.png" alt="Image of Step 5.8" />
​       <br />
​         <strong>Step 5.9.</strong> Log in IBM Cloud account &gt; select Watson Assistant &gt; Click Service credentials &gt; Click the arrow to view your credential &gt; copy apikey, and past it to ASSISTANT_APIKEY and ASSISTANT_IAM_APIKEY &gt; cope url, and past it to ASSISTANT_URL. Please complete others, and save it.
​       <br />
​         <img src="../../assets/figures/dialogue_understanding/Step%205.9.png" alt="Image of Step 5.9" />
​       <br />
​       <br />
​       <br />
​         <strong>Step 5.10.</strong> Open Unity, and let’s play it. 
​       <br />
​         <strong>Note:</strong> You may find it’s different from that you tried it in IBM Watson. For example, the assistant doesn’t automatically jump to the next sentence that we added response types (i.e. Do you need a menu?). The option we created in the menu node also doesn’t work in Unity. Therefore, you need to create more nodes for options. 
​</p>

  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">The Open Augmented Reality Teaching Book</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>The Open Augmented Reality Teaching Book</li>
          <li><a href="mailto:klamma@dbis.rwth-aachen.de">klamma@dbis.rwth-aachen.de</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          <li>
            <a href="https://twitter.com/AR_FOR_EU"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">AR_FOR_EU</span></a>

          </li>
          <li>
            <a href="/ar-for-eu-book/feed.xml"><span class="icon icon-rss"><?xml version="1.0"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"> 
<svg xmlns="http://www.w3.org/2000/svg" version="1.1" width="128px" height="128px" id="RSSicon" viewBox="0 0 256 256">
<defs>
<linearGradient x1="0.085" y1="0.085" x2="0.915" y2="0.915" id="RSSg">
<stop  offset="0.0" stop-color="#E3702D"/><stop  offset="0.1071" stop-color="#EA7D31"/>
<stop  offset="0.3503" stop-color="#F69537"/><stop  offset="0.5" stop-color="#FB9E3A"/>
<stop  offset="0.7016" stop-color="#EA7C31"/><stop  offset="0.8866" stop-color="#DE642B"/>
<stop  offset="1.0" stop-color="#D95B29"/>
</linearGradient>
</defs>
<rect width="256" height="256" rx="55" ry="55" x="0"  y="0"  fill="#CC5D15"/>
<rect width="246" height="246" rx="50" ry="50" x="5"  y="5"  fill="#F49C52"/>
<rect width="236" height="236" rx="47" ry="47" x="10" y="10" fill="url(#RSSg)"/>
<circle cx="68" cy="189" r="24" fill="#FFF"/>
<path d="M160 213h-34a82 82 0 0 0 -82 -82v-34a116 116 0 0 1 116 116z" fill="#FFF"/>
<path d="M184 213A140 140 0 0 0 44 73 V 38a175 175 0 0 1 175 175z" fill="#FFF"/>
</svg>
</span><span class="username">Subscribe</span></a>

          </li>
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>The Open Augmented Reality Teaching Book</p>
      </div>
    </div>

  </div>

</footer>


    <!-- load visualizations (at the end so that the div elements are known here) -->
    
  </body>

</html>
